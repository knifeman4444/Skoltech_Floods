root_path: "your_root_path"
save_model_path: "models"
debug: True
progress_bar: True
device: "cuda:0"
exp_short_description: "baseline"
wandb_log: False

train:
  #mixed_precision?
  dataset_path: "train"
  model_ckpt: null
  num_workers: 0
  shuffle: True
  drop_last: True
  epochs: 25
  log_steps: 10
  patience: 100000

train_model:
  #dropout: 0.1
  backbone: "timm-efficientnet-b5"
  pretrain: "imagenet"
  num_channels: 10

train_params:
  batch_size: 64
  learning_rate: 0.0001
  tile_size: 256
  #TODO lr scheduler

val:
  dataset_path: "train"
  save_val_outputs: True
  batch_size: 64
  num_workers: 0
  shuffle: False
  drop_last: False
  output_dir: "outputs_val"

#TODO
test:
  dataset_path: "train"
  save_test_outputs: True
  model_ckpt: null
  batch_size: 64
  num_workers: 0
  shuffle: False
  drop_last: False
  output_dir: "outputs_test"
